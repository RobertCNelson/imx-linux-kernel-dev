From 63f6af11fb02d80b71ba9d0ff9c1e1759707babc Mon Sep 17 00:00:00 2001
From: Robert Nelson <robertcnelson@gmail.com>
Date: Thu, 17 Sep 2015 15:44:18 -0500
Subject: [PATCH 19/97] apply backport patch
 collateral-evolutions/media/0005-dma-no-sync/v4l2.patch

---
 backports/drivers/media/v4l2-core/videobuf2-dma-contig.c | 4 ++++
 backports/drivers/media/v4l2-core/videobuf2-dma-sg.c     | 8 ++++++++
 2 files changed, 12 insertions(+)

diff --git a/backports/drivers/media/v4l2-core/videobuf2-dma-contig.c b/backports/drivers/media/v4l2-core/videobuf2-dma-contig.c
index fb8533a..b9978dd 100644
--- a/backports/drivers/media/v4l2-core/videobuf2-dma-contig.c
+++ b/backports/drivers/media/v4l2-core/videobuf2-dma-contig.c
@@ -570,7 +570,9 @@ static void vb2_dc_put_userptr(void *buf_priv)
 	if (sgt) {
 		DEFINE_DMA_ATTRS(attrs);
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
 		dma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);
+#endif
 		/*
 		 * No need to sync to CPU, it's already synced to the CPU
 		 * since the finish() memop will have been called before this.
@@ -635,7 +637,9 @@ static void *vb2_dc_get_userptr(void *alloc_ctx, unsigned long vaddr,
 	unsigned long dma_align = dma_get_cache_alignment();
 	DEFINE_DMA_ATTRS(attrs);
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
 	dma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);
+#endif
 
 	/* Only cache aligned DMA transfers are reliable */
 	if (!IS_ALIGNED(vaddr | size, dma_align)) {
diff --git a/backports/drivers/media/v4l2-core/videobuf2-dma-sg.c b/backports/drivers/media/v4l2-core/videobuf2-dma-sg.c
index 2e97c14..6413241 100644
--- a/backports/drivers/media/v4l2-core/videobuf2-dma-sg.c
+++ b/backports/drivers/media/v4l2-core/videobuf2-dma-sg.c
@@ -109,7 +109,9 @@ static void *vb2_dma_sg_alloc(void *alloc_ctx, unsigned long size,
 	int num_pages;
 	DEFINE_DMA_ATTRS(attrs);
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
 	dma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);
+#endif
 
 	if (WARN_ON(alloc_ctx == NULL))
 		return NULL;
@@ -184,7 +186,9 @@ static void vb2_dma_sg_put(void *buf_priv)
 	if (atomic_dec_and_test(&buf->refcount)) {
 		DEFINE_DMA_ATTRS(attrs);
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
 		dma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);
+#endif
 		dprintk(1, "%s: Freeing buffer of %d pages\n", __func__,
 			buf->num_pages);
 		dma_unmap_sg_attrs(buf->dev, sgt->sgl, sgt->nents,
@@ -241,7 +245,9 @@ static void *vb2_dma_sg_get_userptr(void *alloc_ctx, unsigned long vaddr,
 	struct sg_table *sgt;
 	DEFINE_DMA_ATTRS(attrs);
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
 	dma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);
+#endif
 
 	buf = kzalloc(sizeof *buf, GFP_KERNEL);
 	if (!buf)
@@ -347,7 +353,9 @@ static void vb2_dma_sg_put_userptr(void *buf_priv)
 	int i = buf->num_pages;
 	DEFINE_DMA_ATTRS(attrs);
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
 	dma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);
+#endif
 
 	dprintk(1, "%s: Releasing userspace buffer of %d pages\n",
 	       __func__, buf->num_pages);
-- 
2.5.1

